{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from Chapter 14 of _Hands on Machine Learning with Scikit-Learn and Tensorflow_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bare 2-step RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](simpleRNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to unroll it 2 steps and set the hidden vector equal to the output vector (a _very_ simple RNN). That is:\n",
    "\n",
    "$$ Y_0 = \\tanh(W_x X_0 + b) $$\n",
    "\n",
    "and  \n",
    "\n",
    "$$ Y_1 = \\tanh(W_x X_1 + W_y Y_0 + b) $$\n",
    "\n",
    "We'll pass batches of inputs in: a numpy array of size `[n_batches, n_inputs]`. That is, we're writing $X_t$ as a row vector, so really $Y_0 = \\tanh(X_0^t W_x^t + b^t),$ but we'll just drop all the transposes. We should have:\n",
    "\n",
    "* $X_0, X_1$: `[n_batches, n_inputs]`\n",
    "* $W_x$: `[n_inputs, n_neurons]`\n",
    "* $W_y$: `[n_neurons, n_neurons]`\n",
    "* $b$: `[1, n_neurons] `\n",
    "\n",
    "($b$ will be broadcast to `[n_batches, n_neurons]`). That means the output will be\n",
    "\n",
    "* $Y_t$: `[n_batches, n_neurons]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wx = tf.Variable(tf.random_normal(shape=[n_inputs, n_neurons], dtype=tf.float32))\n",
    "Wy = tf.Variable(tf.random_normal(shape=[n_neurons, n_neurons], dtype=tf.float32))\n",
    "b = tf.Variable(tf.zeros([1, n_neurons], dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = tf.tanh(tf.matmul(X0, Wx) + b)\n",
    "Y1 = tf.tanh(tf.matmul(Y0, Wy) + tf.matmul(X1, Wx) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_batch = np.array([[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 0, 1]])\n",
    "X1_batch = np.array([[9, 8, 7], [0, 0, 0], [6, 5, 4], [3, 2, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, the following (first) output of the RNN should be a numpy array of size `[n_batches, n_neurons] = [4, 5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "[[ 0.8960636  -0.9961354   0.9960467  -0.9680858   0.44344255]\n",
      " [ 0.4309014  -1.          0.9999999  -0.9999996  -0.8754126 ]\n",
      " [-0.4852839  -1.          1.         -1.         -0.99660254]\n",
      " [-0.97851205 -0.999997   -0.969897   -0.34225827 -0.9942562 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val.shape)\n",
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same for the following (second) output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "[[-0.9999995  -1.          1.         -1.         -0.99999994]\n",
      " [-0.69430953  0.9957111  -0.9075036  -0.4842649  -0.95532596]\n",
      " [-0.99352264 -0.9999998   0.99997026 -1.         -0.99999714]\n",
      " [-0.9733558  -0.9990728   0.97920734 -0.9783926  -0.9841459 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val.shape)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static 2-step Unrolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0 = tf.placeholder(tf.float32, [None, n_inputs])\n",
    "X1 = tf.placeholder(tf.float32, [None, n_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)  # replaces the deprecated tf.contrib.rnn.BasicRNNCell\n",
    "output_seq, states = tf.contrib.rnn.static_rnn(basic_cell, [X0, X1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0, Y1 = output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()  # this needs to be defined here... defining it before the variables does bad things.\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    Y0_val, Y1_val = sess.run([Y0, Y1], feed_dict={X0: X0_batch, X1: X1_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "[[ 0.26076204 -0.87741923  0.9683349   0.87098503 -0.67625916]\n",
      " [ 0.9233953  -0.9907382   0.999999    0.9835779  -0.99912375]\n",
      " [ 0.99460393 -0.9993372   1.          0.998014   -0.99999803]\n",
      " [ 0.9606342   0.34861976  0.9994729  -0.9944234  -0.9970318 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y0_val.shape)\n",
    "print(Y0_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n",
      "[[ 0.99945015 -0.9993708   1.          0.984867   -0.9999999 ]\n",
      " [ 0.13449268 -0.9358899   0.5924583   0.74528295 -0.60351944]\n",
      " [ 0.98775476 -0.9950965   0.99999994  0.941673   -0.9999885 ]\n",
      " [ 0.48508894 -0.589504    0.94871217  0.7335965  -0.9837607 ]]\n"
     ]
    }
   ],
   "source": [
    "print(Y1_val.shape)\n",
    "print(Y1_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static n-step Unrolling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's rewrite the above in a more scalable way. The input will be a placeholder of shape `[batch_size, n_steps, n_inputs]`, which in TensorFlow can be writte `[None, n_steps, n_inputs]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second argument to `tf.contrib.rnn.static_rnn` should be the list `[X0, X1, ...]`. Each `X_j` is, as above, a tensor of shape `[batch_size, n_inputs]`, that is, a tensor of shape `[None, n_inputs]`. So we have to massage `X` into such a list. \n",
    "\n",
    "We can use `tf.unstack` for this; it turns a tensor of shape `(A, B, C)` into a list of tensors of shape `(B, C)`, where the `i`-th component of the list is the tensor at `A = i`. We want to unstack along `B` (so that we get shape `[None, n_inputs]`), so we'll also pass `axis=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_seqs = tf.unstack(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "output_seqs, states = tf.contrib.rnn.static_rnn(basic_cell, X_seqs, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check that each of the `n_steps` outputs has the expected shape `[None, n_neurons]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(5)])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_seqs[0].get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we restack the outputs into a single tensor so that our output has shape `[None, n_steps, n_neurons]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.stack(output_seqs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(2), Dimension(5)])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.get_shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try it out. Here's a batch of input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],  # instance 0 time steps 1 and 2\n",
    "    [[3, 4, 5], [0, 0, 0]],  # instance 1\n",
    "    [[6, 7, 8], [6, 5, 4]],  # instance 2\n",
    "    [[9, 0, 1], [3, 2, 1]],  # instance 3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.9499117   0.14086019  0.6971834  -0.2441735   0.45512706]\n",
      "  [-0.9373555  -0.99562085  0.9999227   0.99250203  0.99996305]]\n",
      "\n",
      " [[-0.9902277  -0.74542236  0.9922384   0.64982086  0.9879935 ]\n",
      "  [-0.8743683   0.7260192  -0.69016814 -0.01985344 -0.6202365 ]]\n",
      "\n",
      " [[-0.9981246  -0.9684646   0.9998299   0.9467215   0.9998052 ]\n",
      "  [-0.8056482  -0.86899126  0.9493427   0.9825388   0.9915183 ]]\n",
      "\n",
      " [[ 0.99998075 -0.9627134   0.98568964  0.03348969  0.99999964]\n",
      "  [-0.05042231 -0.9036694   0.18797247  0.9902675   0.94957983]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Unrolling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following does the same thing as the above code (although `dynamic_rnn` does some magic during backprop and can swap gpu  to cpu memory to avoid OOM for large `n_steps` if you set `swap_memory=True`). \n",
    "\n",
    "It handles the stacking and unstacking internally, and takes an input of shape `[None, n_steps, n_inputs]` and outputs a shape `[None, n_steps, n_neurons]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 2\n",
    "n_inputs = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "\n",
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    [[0, 1, 2], [9, 8, 7]],  # instance 0 time steps 1 and 2\n",
    "    [[3, 4, 5], [0, 0, 0]],  # instance 1\n",
    "    [[6, 7, 8], [6, 5, 4]],  # instance 2\n",
    "    [[9, 0, 1], [3, 2, 1]],  # instance 3\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val = outputs.eval(feed_dict={X: X_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify: outputs_val should have shape `[4, 2, 5]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.8751525   0.6505132   0.9486273   0.29616487  0.18506825]\n",
      "  [-0.73852015  0.9586125   1.          0.9964853  -0.98769546]]\n",
      "\n",
      " [[-0.9790082   0.8880114   0.9999992   0.9325753  -0.26518932]\n",
      "  [ 0.70313865  0.3969653   0.14452802 -0.48861504 -0.9158057 ]]\n",
      "\n",
      " [[-0.9966259   0.96731114  1.          0.99552685 -0.6234261 ]\n",
      "  [ 0.5791816   0.5963608   1.          0.9531009  -0.99148005]]\n",
      "\n",
      " [[ 0.9999642   0.6567935   0.9999989   0.99999505 -0.99985355]\n",
      "  [ 0.74507666 -0.9035656   0.9998165   0.14869687 -0.89989984]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable-length Sequences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to pass a list of sequence lengths to `dynamic_rnn` if we want to handle sequences of variable length. \n",
    "\n",
    "The input should still be of shape `[None, n_steps, n_inputs]`, but we set `n_steps = max(seq_length)` and zero pad shorter sequences. So if we want to pass the four sequences\n",
    "```\n",
    "[0, 1, 2], [9, 8, 7], [6, 5, 4]  # seq of length 3\n",
    "[1, 1, 0]  # seq of length 1\n",
    "[1, 2, 3], [5, 8, 7]  # seq of length 2\n",
    "[1, 2, 2], [3, 3, 1], [1, 2, 3]  # seq of length 3\n",
    "```\n",
    "we set our batch to be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch = np.array([\n",
    "    [[0, 1], [9, 8], [6, 5]],  # seq 0\n",
    "    [[1, 1], [0, 0], [0, 0]],  # seq 1\n",
    "    [[1, 2], [5, 8], [0, 0]],  # seq 2\n",
    "    [[1, 2], [3, 3], [1, 2]]\n",
    "])\n",
    "seq_length_batch = np.array([3, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2\n",
    "n_steps = 3\n",
    "n_neurons = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, X, dtype=tf.float32, sequence_length=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    outputs_val, states_val = sess.run([outputs, states], feed_dict={X: X_batch, seq_length: seq_length_batch})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the outputs, we should see the second output (`Y_1`) a length-1 sequence of length-5 vectors with zero padding (i.e., 2 length-5 zero vectors). The third output (`Y_2`) should be a length-2 sequence with 1 zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.58838236 -0.64997005 -0.10364981  0.63065267  0.1784632 ]\n",
      "  [ 1.          0.71209157  0.8756396   1.          0.84044   ]\n",
      "  [ 0.9999993   0.7827625  -0.65074587  0.99999976  0.8607044 ]]\n",
      "\n",
      " [[ 0.87019324  0.03839012  0.15967356  0.91743726  0.20589276]\n",
      "  [ 0.          0.          0.          0.          0.        ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9646623  -0.6272309   0.05696655  0.9806825   0.37073362]\n",
      "  [ 0.9999999  -0.9847217  -0.15901498  0.99999994  0.7748732 ]\n",
      "  [ 0.          0.          0.          0.          0.        ]]\n",
      "\n",
      " [[ 0.9646623  -0.6272309   0.05696655  0.9806825   0.37073362]\n",
      "  [ 0.99832606 -0.18241285 -0.16877857  0.9983101   0.07333673]\n",
      "  [ 0.9529912  -0.8083575  -0.61593825  0.90920126 -0.4004553 ]]]\n"
     ]
    }
   ],
   "source": [
    "print(outputs_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point: in this `SimpleRNNCell`, the hidden state is just the last output vector. So if we want the final states for each entry in the batch, we can just look at `states_val`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9999993   0.7827625  -0.65074587  0.99999976  0.8607044 ]\n",
      " [ 0.87019324  0.03839012  0.15967356  0.91743726  0.20589276]\n",
      " [ 0.9999999  -0.9847217  -0.15901498  0.99999994  0.7748732 ]\n",
      " [ 0.9529912  -0.8083575  -0.61593825  0.90920126 -0.4004553 ]]\n"
     ]
    }
   ],
   "source": [
    "print(states_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that it handled the zero-padding correctly. It picked of the _final_ states given the `seq_length`s, not just the highest-index state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
