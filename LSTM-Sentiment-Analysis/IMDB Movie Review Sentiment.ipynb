{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from https://github.com/adeshpande3/LSTM-Sentiment-Analysis/blob/master/Oriole%20LSTM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_base_dir = os.path.join('d:', os.sep, 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(dim=50, filename=None):\n",
    "    if dim in (50, 100, 200, 300) and filename is None:\n",
    "        filename = os.path.join(dataset_base_dir, 'glove', 'glove.6B.{}d.txt'.format(dim))\n",
    "    else:\n",
    "        logger.error('invalid dimension: please choose from 50, 100, 200, 300')\n",
    "    \n",
    "    with open(filename, encoding='utf-8') as f:\n",
    "        lines = f.read().split('\\n')[:-1]  # last line is empty\n",
    "\n",
    "    word_list = [line.split(' ')[0] for line in lines]    \n",
    "    word_vectors = [np.array(list(map(np.float, line.split(' ')[1:]))) for line in lines]\n",
    "    \n",
    "    return word_list, np.array(word_vectors)\n",
    "\n",
    "word_list, word_vectors = load_glove_vectors()\n",
    "\n",
    "word_list = ['//UNK', '//PAD', '//END'] + word_list\n",
    "unk_vector = np.full((word_dim,), fill_value=-50)\n",
    "pad_vector = np.full((word_dim,), fill_value=-100)\n",
    "end_vector = np.full((word_dim,), fill_value=-150)\n",
    "word_vectors = np.vstack([unk_vector, pad_vector, end_vector, word_vectors])\n",
    "\n",
    "def word2vec(word):\n",
    "    return word_vectors[word_list.index(word)]\n",
    "\n",
    "def word2idx(word):\n",
    "    try:\n",
    "        return word_list.index(word)\n",
    "    except:  # return the //UNK token if word isn't in the vocabulary\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400003, (400003, 50))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_list), word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//UNK', '//PAD', '//END', 'the', ',', '.', 'of', 'to', 'and', 'in']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx('//PAD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-50., -50., -50., -50., -50., -50., -50., -50., -50., -50., -50.,\n",
       "       -50., -50., -50., -50., -50., -50., -50., -50., -50., -50., -50.,\n",
       "       -50., -50., -50., -50., -50., -50., -50., -50., -50., -50., -50.,\n",
       "       -50., -50., -50., -50., -50., -50., -50., -50., -50., -50., -50.,\n",
       "       -50., -50., -50., -50., -50., -50.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.9327  ,  1.0421  , -0.78515 ,  0.91033 ,  0.22711 , -0.62158 ,\n",
       "       -1.6493  ,  0.07686 , -0.5868  ,  0.058831,  0.35628 ,  0.68916 ,\n",
       "       -0.50598 ,  0.70473 ,  1.2664  , -0.40031 , -0.020687,  0.80863 ,\n",
       "       -0.90566 , -0.074054, -0.87675 , -0.6291  , -0.12685 ,  0.11524 ,\n",
       "       -0.55685 , -1.6826  , -0.26291 ,  0.22632 ,  0.713   , -1.0828  ,\n",
       "        2.1231  ,  0.49869 ,  0.066711, -0.48226 , -0.17897 ,  0.47699 ,\n",
       "        0.16384 ,  0.16537 , -0.11506 , -0.15962 , -0.94926 , -0.42833 ,\n",
       "       -0.59457 ,  1.3566  , -0.27506 ,  0.19918 , -0.36008 ,  0.55667 ,\n",
       "       -0.70315 ,  0.17157 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec('baseball')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx('this'), word2idx('fdsahjk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 10\n",
    "dim = 50\n",
    "first_sentence = 'i thought the movie was incredible and inspiring'\n",
    "first_sentence_ids = np.zeros(max_seq_length, dtype='int32')\n",
    "for j, word in enumerate(first_sentence.split()):\n",
    "    first_sentence_ids[j] = word_list.index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(tf.nn.embedding_lookup(word_vectors, first_sentence_ids).eval().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(dataset_base_dir, 'imdb-movie-reviews')\n",
    "\n",
    "pos_train = os.path.join(dataset_dir, 'train', 'pos')\n",
    "neg_train = os.path.join(dataset_dir, 'train', 'neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_train_filenames = [os.path.join(pos_train, filename) \n",
    "                       for filename in os.listdir(pos_train)\n",
    "                       if os.path.isfile(os.path.join(pos_train, filename))]\n",
    "neg_train_filenames = [os.path.join(neg_train, filename)\n",
    "                       for filename in os.listdir(neg_train)\n",
    "                       if os.path.isfile(os.path.join(neg_train, filename))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 12500)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pos_train_filenames), len(neg_train_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = []\n",
    "for filename in pos_train_filenames + neg_train_filenames:\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "            word_counts.append(len(f.read().split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, [140, 428, 147, 124, 120, 171, 108, 340, 436, 324])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counts), word_counts[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 936x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ymax = 7300\n",
    "\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "sns.distplot(word_counts, kde=False);\n",
    "plt.xlabel('Number of Words');\n",
    "plt.ylabel('Number of Reviews');\n",
    "plt.ylim(0, ymax);\n",
    "plt.vlines(x=500, ymin=0, ymax=ymax, colors='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_review(filename, seq_length=max_seq_length):\n",
    "    filename_base = filename.split('.')[0].split('\\\\')[-1]\n",
    "    review_idx, review_rating = filename_base.split('_')\n",
    "    \n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        text = f.read().lower()\n",
    "    \n",
    "    token_rgx = re.compile(r\"\\w+|[^\\w\\s]\")\n",
    "    \n",
    "    tokens = token_rgx.findall(text)\n",
    "    review_len = len(tokens)\n",
    "    \n",
    "    word_ids = np.full(seq_length, fill_value=word2idx('//PAD'), dtype='int32')\n",
    "    for j in range(min(review_len, seq_length)):\n",
    "        word_ids[j] = word2idx(tokens[j])\n",
    "    if review_len < seq_length:\n",
    "        word_ids[review_len] = word2idx('//END')\n",
    "        \n",
    "    return review_idx, int(review_rating), review_len, word_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0',\n",
       " 9,\n",
       " 185,\n",
       " array([174946,    155,     17,     10,   7365,   2844,      5,     23,\n",
       "          1424,     25,      3,    218,     82,     22,     80,     71,\n",
       "          1012,     62,    167,    217,      4,    128,     22,     11,\n",
       "          2565,     11,      5,    195,   1681,     85,      9,      3,\n",
       "          3177,   8107,    413,    288,      7,    736,     15, 174946,\n",
       "           155,     60,   1537,  15306,     17,    184,   2389,      7,\n",
       "          2535,     76,     17,     11,   2565,     11,      5,      3,\n",
       "         14173,      7,   3984,   7983,      4,      3,  34404,    546,\n",
       "            41,     89,    256,    251,    134,     47,  22498,   2565,\n",
       "            60,  31169,      4,      3,  91890,      6,      3,   1118,\n",
       "           797,      4,     67,   9797,    288,      6,      3,    891,\n",
       "            44,   1525,      8,     47,    546,      5,     64,     44,\n",
       "           825,      3,   1945,      9,     45,     10,   1286,   2651,\n",
       "           980,      7,   6295,    138,      3,    167,      4,     44,\n",
       "          1043,   3154,      5,      5,      5,      5,      5,      5,\n",
       "             5,      5,      5,     25,      5,      5,      5,      5,\n",
       "             5,      5,      5,      5,      5,      5,    155,      5,\n",
       "            10,   2395,    334,     48,   5540,     48,     44,     60,\n",
       "          1996,    190,      7,  11742,     51,      6,    395,   2565,\n",
       "             5,   1286,     48,   3146,      7, 174946,    155,      5,\n",
       "            44,   1546,     15,    112,   3577,      6,    195,    467,\n",
       "           272,     15, 174946,    155,     17,    375,  19389,      5,\n",
       "           105,     10,  16217,     15,     23,  75363,     60,   2162,\n",
       "           808,      2,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1,      1,      1,      1,      1,\n",
       "             1,      1,      1,      1]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_review(pos_train_filenames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2680"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a review w more than max_seq_length words\n",
    "word_counts.index(max_seq_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,) (10,)\n"
     ]
    }
   ],
   "source": [
    "print(load_review(pos_train_filenames[2680])[3].shape, \n",
    "load_review(pos_train_filenames[2680], seq_length=10)[3].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reviews(seq_length=max_seq_length):\n",
    "    num_reviews = len(pos_train_filenames) + len(neg_train_filenames)\n",
    "    ratings = np.zeros(num_reviews)\n",
    "    review_lengths = np.zeros(num_reviews)\n",
    "    reviews = np.zeros((num_reviews, seq_length))\n",
    "    \n",
    "    for j, filename in enumerate(tqdm(pos_train_filenames + neg_train_filenames)):\n",
    "        _, ratings[j], review_lengths[j], reviews[j] = load_review(filename, seq_length)\n",
    "        \n",
    "    return np.array(ratings), np.array(review_lengths), reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_filename = '_data/imdb_{}_glove{}.npz'.format(max_seq_length, word_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile(npz_filename):\n",
    "    with open(npz_filename, 'rb') as f:\n",
    "        npzfile = np.load(f)\n",
    "        ratings, review_lengths, reviews = npzfile['arr_0'], npzfile['arr_1'], npzfile['arr_2']\n",
    "else:\n",
    "    ratings, review_lengths, reviews = load_reviews()\n",
    "    with open(npz_filename, 'wb') as f:\n",
    "        np.savez(f, ratings, review_lengths, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000,), (25000,), (25000, 500))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.shape, review_lengths.shape, reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0,\n",
       " 185.0,\n",
       " array([1.74946e+05, 1.55000e+02, 1.70000e+01, 1.00000e+01, 7.36500e+03,\n",
       "        2.84400e+03, 5.00000e+00, 2.30000e+01, 1.42400e+03, 2.50000e+01,\n",
       "        3.00000e+00, 2.18000e+02, 8.20000e+01, 2.20000e+01, 8.00000e+01,\n",
       "        7.10000e+01, 1.01200e+03, 6.20000e+01, 1.67000e+02, 2.17000e+02,\n",
       "        4.00000e+00, 1.28000e+02, 2.20000e+01, 1.10000e+01, 2.56500e+03,\n",
       "        1.10000e+01, 5.00000e+00, 1.95000e+02, 1.68100e+03, 8.50000e+01,\n",
       "        9.00000e+00, 3.00000e+00, 3.17700e+03, 8.10700e+03, 4.13000e+02,\n",
       "        2.88000e+02, 7.00000e+00, 7.36000e+02, 1.50000e+01, 1.74946e+05,\n",
       "        1.55000e+02, 6.00000e+01, 1.53700e+03, 1.53060e+04, 1.70000e+01,\n",
       "        1.84000e+02, 2.38900e+03, 7.00000e+00, 2.53500e+03, 7.60000e+01,\n",
       "        1.70000e+01, 1.10000e+01, 2.56500e+03, 1.10000e+01, 5.00000e+00,\n",
       "        3.00000e+00, 1.41730e+04, 7.00000e+00, 3.98400e+03, 7.98300e+03,\n",
       "        4.00000e+00, 3.00000e+00, 3.44040e+04, 5.46000e+02, 4.10000e+01,\n",
       "        8.90000e+01, 2.56000e+02, 2.51000e+02, 1.34000e+02, 4.70000e+01,\n",
       "        2.24980e+04, 2.56500e+03, 6.00000e+01, 3.11690e+04, 4.00000e+00,\n",
       "        3.00000e+00, 9.18900e+04, 6.00000e+00, 3.00000e+00, 1.11800e+03,\n",
       "        7.97000e+02, 4.00000e+00, 6.70000e+01, 9.79700e+03, 2.88000e+02,\n",
       "        6.00000e+00, 3.00000e+00, 8.91000e+02, 4.40000e+01, 1.52500e+03,\n",
       "        8.00000e+00, 4.70000e+01, 5.46000e+02, 5.00000e+00, 6.40000e+01,\n",
       "        4.40000e+01, 8.25000e+02, 3.00000e+00, 1.94500e+03, 9.00000e+00,\n",
       "        4.50000e+01, 1.00000e+01, 1.28600e+03, 2.65100e+03, 9.80000e+02,\n",
       "        7.00000e+00, 6.29500e+03, 1.38000e+02, 3.00000e+00, 1.67000e+02,\n",
       "        4.00000e+00, 4.40000e+01, 1.04300e+03, 3.15400e+03, 5.00000e+00,\n",
       "        5.00000e+00, 5.00000e+00, 5.00000e+00, 5.00000e+00, 5.00000e+00,\n",
       "        5.00000e+00, 5.00000e+00, 5.00000e+00, 2.50000e+01, 5.00000e+00,\n",
       "        5.00000e+00, 5.00000e+00, 5.00000e+00, 5.00000e+00, 5.00000e+00,\n",
       "        5.00000e+00, 5.00000e+00, 5.00000e+00, 5.00000e+00, 1.55000e+02,\n",
       "        5.00000e+00, 1.00000e+01, 2.39500e+03, 3.34000e+02, 4.80000e+01,\n",
       "        5.54000e+03, 4.80000e+01, 4.40000e+01, 6.00000e+01, 1.99600e+03,\n",
       "        1.90000e+02, 7.00000e+00, 1.17420e+04, 5.10000e+01, 6.00000e+00,\n",
       "        3.95000e+02, 2.56500e+03, 5.00000e+00, 1.28600e+03, 4.80000e+01,\n",
       "        3.14600e+03, 7.00000e+00, 1.74946e+05, 1.55000e+02, 5.00000e+00,\n",
       "        4.40000e+01, 1.54600e+03, 1.50000e+01, 1.12000e+02, 3.57700e+03,\n",
       "        6.00000e+00, 1.95000e+02, 4.67000e+02, 2.72000e+02, 1.50000e+01,\n",
       "        1.74946e+05, 1.55000e+02, 1.70000e+01, 3.75000e+02, 1.93890e+04,\n",
       "        5.00000e+00, 1.05000e+02, 1.00000e+01, 1.62170e+04, 1.50000e+01,\n",
       "        2.30000e+01, 7.53630e+04, 6.00000e+01, 2.16200e+03, 8.08000e+02,\n",
       "        2.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00,\n",
       "        1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings[0], review_lengths[0], reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size):\n",
    "    # just do random batches for now\n",
    "    idxs = np.random.randint(0, ratings.shape[0], batch_size)\n",
    "    \n",
    "    # since we want pos/neg and pos is >= 7.0 stars, we'll convert to 1 (pos) vs 0 (neg) labels\n",
    "    return reviews[idxs, :], review_lengths[idxs], np.array(ratings[idxs] >= 7.0, dtype='int32')\n",
    "\n",
    "def get_test_batch(batch_size):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logdir(name):\n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    root_logdir = 'tf_logs' + name\n",
    "    logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "    return logdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "n_neurons = 11\n",
    "n_steps = 5\n",
    "\n",
    "droupout_keep_prob = 0.75\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the basic RNN cell takes a tensor of shape `[None, n_steps, n_inputs]` where `None` will be the batch size, and we set `n_steps = max_seq_length`. That is, it should be `[None, 500, word_dim]`.\n",
    "\n",
    "The output should be `[None, 500, n_neurons]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, max_seq_length])  # the batch of reviews (as zero-padded seqs of word idxs)\n",
    "seq_length = tf.placeholder(tf.int32, [None])\n",
    "y = tf.placeholder(tf.int32, [None])  # the batch of review labels (-1=bad, 1=good)\n",
    "\n",
    "vector_data = tf.cast(tf.nn.embedding_lookup(word_vectors, X), dtype=tf.float32)  # the batch of reviews as zero-padded seqs of word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(500), Dimension(50)])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_data.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "basic_cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "outputs, states = tf.nn.dynamic_rnn(basic_cell, vector_data, dtype=tf.float32, sequence_length=seq_length)\n",
    "\n",
    "# lstm_cell = tf.nn.rnn_cell.LSTMCell(lstm_units, dtype=tf.float32)\n",
    "# lstm_cell = tf.contrib.rnn.DropoutWrapper(cell=lstm_cell, output_keep_prob=droupout_keep_prob, dtype=tf.float32)\n",
    "# initial_state = lstm_cell.zero_state(batch_size, dtype=tf.float32)\n",
    "# outputs, states = tf.nn.dynamic_rnn(lstm_cell, data, initial_state=initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the states output of a SimpleRNNCell is the last output state, we'll feed that into a fully connected layer to compute the logits (with 2 classes: `0=bad`, `1=good`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = tf.contrib.layers.fully_connected(states, 2, activation_fn=None)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "loss_summary = tf.summary.scalar('Loss', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_op = optimizer.minimize(loss)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "acc_summary = tf.summary.scalar('Accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "file_writer = tf.summary.FileWriter(logdir('_imdb'), tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: for a very lucid explanation of what is happening here, see _Hands-on Machine Learning with Scikit-learn and TensorFlow_, Chapter 14 (Training a Sequence Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Train accuracy: 0.6\n",
      "1 Train accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2\n",
    "batch_size = 10\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(100):\n",
    "            batch_data, batch_lengths, batch_labels = get_batch(batch_size)\n",
    "            sess.run(training_op, feed_dict={X: batch_data, seq_length: batch_lengths, y: batch_labels})\n",
    "            # sample_outputs = outputs.eval(feed_dict={X: batch_data, seq_length: batch_lengths})\n",
    "            if iteration % 10 == 0:\n",
    "                summary_str\n",
    "        acc_train = accuracy.eval(feed_dict={X: batch_data, seq_length: batch_lengths, y: batch_labels})\n",
    "        print(epoch, \"Train accuracy:\", acc_train)\n",
    "        \n",
    "filewriter.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo\n",
    "1. filewriter for tensorboard\n",
    "2. classify some specific examples for sanity checking\n",
    "3. replace SimpleRNNCell with an LSTM\n",
    "4. compare to a baseline logistic regression with hand-curated tokens\n",
    "5. compare glove vectors of different sizes and maybe google w2v vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logdir(name):\n",
    "    now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "    root_logdir = 'tf_logs' + name\n",
    "    logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "    return logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "file_writer = tf.summary.FileWriter(logdir('_imdb'), tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (24,) for Tensor 'Placeholder:0', which has shape '(24, 1)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-6feda27ad671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 loss, loss_summary_str, acc_summary_str = sess.run([loss, loss_summary, acc_summary],\n\u001b[0;32m     14\u001b[0m                                                                   feed_dict={input_data: batch_data,\n\u001b[1;32m---> 15\u001b[1;33m                                                                              labels: batch_labels})\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbatch_number\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                 \u001b[0mfile_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_summary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\toolkits\\Anaconda3-5.2.0\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\toolkits\\Anaconda3-5.2.0\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1128\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1129\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (24,) for Tensor 'Placeholder:0', which has shape '(24, 1)'"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "n_batches = len(reviews) // batch_size\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_number in range(n_batches):\n",
    "            batch_data, batch_labels = get_batch(batch_size)\n",
    "            if batch_number % 10 == 0:\n",
    "                # log stuff to file_writer\n",
    "                loss, loss_summary_str, acc_summary_str = sess.run([loss, loss_summary, acc_summary],\n",
    "                                                                  feed_dict={input_data: batch_data,\n",
    "                                                                             labels: batch_labels})\n",
    "                step = epoch * n_batches + batch_number\n",
    "                file_writer.add_summary(loss_summary_str, step)\n",
    "                file_writer.add_summary(acc_summary_str, step)\n",
    "                \n",
    "            sess.run(training_op, feed_dict={input_data: batch_data, labels: batch_labels})\n",
    "        \n",
    "        # console output to see progress\n",
    "        acc_train = accuracy.eval(feed_dict={input_data: batch_data, labels: batch_labels})\n",
    "        print(epoch, 'batch accuracy:', acc_train)\n",
    "    \n",
    "    save_path = saver.save(sess, './imdb_lstm.ckpt')\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print('Finished in {}s.'.format(end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
